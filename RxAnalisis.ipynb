{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd02030",
   "metadata": {},
   "source": [
    "# RADIOGRAFÍAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6988e1a",
   "metadata": {},
   "source": [
    "### Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b41c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes de imagen\n",
    "import SimpleITK as sitk\n",
    "from skimage import exposure\n",
    "\n",
    "# Paquetes de df y arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Del propio paquete\n",
    "from downloaddata import fetch_data as fdata\n",
    "\n",
    "# OS\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "image_viewer = sitk.ImageViewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a85df2",
   "metadata": {},
   "source": [
    "### Lector de imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3c1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiji = 'D:/Users/María Rollán/Documents/Fiji.app/ImageJ-win64.exe'\n",
    "image_viewer.SetApplication(fiji)\n",
    "ctFolder = 'Vessel_stencils'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026bdfe",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4908efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configura el logging\n",
    "log_format = '[%(process)d]\\t%(asctime)s %(levelname)s: %(message)s'\n",
    "logging.basicConfig(format=log_format, level=logging.INFO, datefmt=\"%H:%M:%S\",\n",
    "                    handlers=[logging.StreamHandler(sys.stdout)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9cd67",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5311d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo(img):\n",
    "    '''\n",
    "    Create a histogram from a SITK image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img (SITK image)\n",
    "    '''\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "    fig = plt.figure(figsize = (7,5))\n",
    "    ax = fig.gca()\n",
    "    ax.hist(arr.flatten(), bins = 255)\n",
    "    plt.show(fig)\n",
    "\n",
    "def plotImg(img, color = 'gray'):\n",
    "    '''\n",
    "    Plot a SITK image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img (SITK image)\n",
    "    color (string): the colour for image representation\n",
    "    '''\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "    plt.imshow(arr, cmap = color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c0299",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be8873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_001.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_001.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           57              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           80              M            PA                 2500     2048   \n",
       "4           74              F            PA                 2500     2048   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  \n",
       "0                        0.143  0.143  \n",
       "1                        0.143  0.143  \n",
       "2                        0.168  0.168  \n",
       "3                        0.171  0.171  \n",
       "4                        0.168  0.168  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CXR8/Data_Entry_2017_v2020.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934895b4",
   "metadata": {},
   "source": [
    "Sacamos los posibles labels que hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8479dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(df['Finding Labels'])\n",
    "labels = '|'.join(labels)\n",
    "labels = labels.split('|')\n",
    "labels = np.unique(labels).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03712b7e",
   "metadata": {},
   "source": [
    "Creamos una nueva columna por cada uno de los labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "144c432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in labels:\n",
    "    df[lab] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb381ee",
   "metadata": {},
   "source": [
    "Creamos una funcion para rellenar esas columnas por cada paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2161b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_label(information, label):\n",
    "    positive_labels = information.split('|')\n",
    "    if label in positive_labels:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd0bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map(objeto enumerado x: funcion(x, y), lista de x)\n",
    "for lab in labels:\n",
    "    df[lab] = list(map(lambda x: fill_label(x, lab), df['Finding Labels'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1780f",
   "metadata": {},
   "source": [
    "## Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63943111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_images(folder):\n",
    "    path = os.path.join(folder, 'images')\n",
    "    images_path = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    images = [sitk.ReadImage(os.path.join(path, image_path)) for image_path in images_path]\n",
    "    data = {'path': images_path, 'image': images}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1981ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [f.path for f in os.scandir('./CXR8/images/') if f.is_dir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05ce38",
   "metadata": {},
   "source": [
    "No se pueden cargar todas las imagenes así que solo he cargado la carpeta 1 y 2 (subfolders[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad357314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./CXR8/images/images_001']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2481177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41052]\t13:07:13 INFO: [F]\tFolder ./CXR8/images/images_001\n",
      "[41052]\t13:09:27 INFO: [F]\tappending\n",
      "[41052]\t13:09:27 INFO: [F]\tstarting\n"
     ]
    }
   ],
   "source": [
    "keys = ['path', 'image']\n",
    "all_images = dict.fromkeys(keys)\n",
    "\n",
    "for folder in subfolders[0:1]:\n",
    "    logging.info('[F]\\tFolder {}'.format(folder))\n",
    "    group = folder.split('/')\n",
    "    folder_info = charge_images(folder)\n",
    "    try:\n",
    "        logging.info('[F]\\tappending')\n",
    "        all_images['path'][0].append(folder_info['path'])\n",
    "        all_images['image'][0].append(folder_info['image'])\n",
    "    except:\n",
    "        logging.info('[F]\\tstarting')\n",
    "        all_images['path'] = folder_info['path']\n",
    "        all_images['image'] = folder_info['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8efe7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = pd.DataFrame(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35b5242a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00006966_004.png</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00007442_018.png</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00008462_002.png</td>\n",
       "      <td>[149, 146, 142, 141, 140, 138, 137, 130, 122, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00008745_019.png</td>\n",
       "      <td>[7, 12, 11, 12, 11, 11, 10, 10, 10, 10, 10, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006590_000.png</td>\n",
       "      <td>[23, 23, 24, 23, 23, 23, 23, 23, 24, 24, 23, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               path                                              image\n",
       "0  00006966_004.png  [4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, ...\n",
       "1  00007442_018.png  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "2  00008462_002.png  [149, 146, 142, 141, 140, 138, 137, 130, 122, ...\n",
       "3  00008745_019.png  [7, 12, 11, 12, 11, 11, 10, 10, 10, 10, 10, 10...\n",
       "4  00006590_000.png  [23, 23, 24, 23, 23, 23, 23, 23, 24, 24, 23, 2..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa85f9",
   "metadata": {},
   "source": [
    "Ahora voy a añadir datos a este nuevo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a37a9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column(path, column):\n",
    "    value = df[column][df['Image Index'] == path]\n",
    "    value = list(value)[0]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f49aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images['neumonia'] = list(map(lambda x: get_column(x, 'Pneumonia'), all_images['path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3573c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "      <th>neumonia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00006966_004.png</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00007442_018.png</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00008462_002.png</td>\n",
       "      <td>[149, 146, 142, 141, 140, 138, 137, 130, 122, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00008745_019.png</td>\n",
       "      <td>[7, 12, 11, 12, 11, 11, 10, 10, 10, 10, 10, 10...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006590_000.png</td>\n",
       "      <td>[23, 23, 24, 23, 23, 23, 23, 23, 24, 24, 23, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               path                                              image  \\\n",
       "0  00006966_004.png  [4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, ...   \n",
       "1  00007442_018.png  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  00008462_002.png  [149, 146, 142, 141, 140, 138, 137, 130, 122, ...   \n",
       "3  00008745_019.png  [7, 12, 11, 12, 11, 11, 10, 10, 10, 10, 10, 10...   \n",
       "4  00006590_000.png  [23, 23, 24, 23, 23, 23, 23, 23, 24, 24, 23, 2...   \n",
       "\n",
       "   neumonia  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56a76528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images['image'][2].GetSize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60443d78",
   "metadata": {},
   "source": [
    "## Filtros sobre imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372afa55",
   "metadata": {},
   "source": [
    "### Equalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d49c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalizar(img):\n",
    "    '''\n",
    "    Equalize a SITK image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img (SITK image)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img (SITK image)    \n",
    "    '''\n",
    "    imgArr = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # Contrast stretching\n",
    "    p2, p98 = np.percentile(imgArr, (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(imgArr, in_range=(p2, p98))\n",
    "\n",
    "    # Equalization\n",
    "    img_eq = exposure.equalize_hist(imgArr)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    img_adapteq = exposure.equalize_adapthist(imgArr, clip_limit=0.03)\n",
    "    logging.info('[F]\\tend equalizar')\n",
    "        \n",
    "    return img_adapteq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdad5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images['equalizado'] = list(map(lambda x: equalizar(x), all_images['image']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f5cb3",
   "metadata": {},
   "source": [
    "## Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f447ec07",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcdb87",
   "metadata": {},
   "source": [
    "Defino el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "515fb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 13:35:29.928574: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 1024, 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPool2D())\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py:202\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    197\u001b[0m     x \u001b[38;5;241m=\u001b[39m input_layer\u001b[38;5;241m.\u001b[39mInput(\n\u001b[1;32m    198\u001b[0m         batch_shape\u001b[38;5;241m=\u001b[39mbatch_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# This will build the current layer\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# and create the node connecting the current layer\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# to the input layer we just created.\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     set_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_inputs:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py:976\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py:1114\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1112\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1113\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1119\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1120\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py:848\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py:886\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_scope()):  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    882\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[0;32m--> 886\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py:2633\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_build\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m   2631\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set before layer building, e.g. input rank.\u001b[39;00m\n\u001b[1;32m   2632\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 2633\u001b[0m     \u001b[43minput_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_input_compatibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2635\u001b[0m     input_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m   2636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype_policy\u001b[38;5;241m.\u001b[39mcompute_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py:229\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    227\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    228\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(input_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    230\u001b[0m                      layer_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: expected min_ndim=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(spec\u001b[38;5;241m.\u001b[39mmin_ndim) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    232\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ndim) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    233\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Full shape received: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    234\u001b[0m                      \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(shape)))\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 1024, 1024)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(1024,1024)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a39999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\María Rollán\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.000001)\n",
    "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e57a94",
   "metadata": {},
   "source": [
    "Cojo X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1ab0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:33 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:33 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:54 INFO: [F]\tend equalizar\n"
     ]
    }
   ],
   "source": [
    "X = list(map(lambda x: equalizar(x), all_images['image'][1:100]))\n",
    "Y = list(all_images['neumonia'][1:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2dbed",
   "metadata": {},
   "source": [
    "Divido en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58fa1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143202c7",
   "metadata": {},
   "source": [
    "Normalizo los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d2a15b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\n\u001b[0;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m      4\u001b[0m X_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, img_size, img_size, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "X_train.reshape(-1, img_size, img_size, 1)\n",
    "Y_train = Y_train\n",
    "\n",
    "X_test.reshape(-1, img_size, img_size, 1)\n",
    "Y_test = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567bf7d",
   "metadata": {},
   "source": [
    "Aumento del train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c47f5",
   "metadata": {},
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056ec0c",
   "metadata": {},
   "source": [
    "Entreno el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68c703d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py:985\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    982\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    984\u001b[0m   \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m--> 985\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    986\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    988\u001b[0m           _type_name(x), _type_name(y)))\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    990\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m           adapter_cls, _type_name(x), _type_name(y)))\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,epochs = 500 , validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac7297",
   "metadata": {},
   "source": [
    "Compruebo el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(500)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "print(classification_report(Y_test, predictions, target_names = ['No neumonia','Neumonia']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
