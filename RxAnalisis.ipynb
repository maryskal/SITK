{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd02030",
   "metadata": {},
   "source": [
    "# RADIOGRAFÍAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6988e1a",
   "metadata": {},
   "source": [
    "### Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b41c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes de imagen\n",
    "import SimpleITK as sitk\n",
    "from skimage import exposure\n",
    "\n",
    "# Paquetes de df y arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Del propio paquete\n",
    "from downloaddata import fetch_data as fdata\n",
    "\n",
    "# OS\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "image_viewer = sitk.ImageViewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a85df2",
   "metadata": {},
   "source": [
    "### Lector de imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3c1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiji = 'D:/Users/María Rollán/Documents/Fiji.app/ImageJ-win64.exe'\n",
    "image_viewer.SetApplication(fiji)\n",
    "ctFolder = 'Vessel_stencils'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026bdfe",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4908efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configura el logging\n",
    "log_format = '[%(process)d]\\t%(asctime)s %(levelname)s: %(message)s'\n",
    "logging.basicConfig(format=log_format, level=logging.INFO, datefmt=\"%H:%M:%S\",\n",
    "                    handlers=[logging.StreamHandler(sys.stdout)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9cd67",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5311d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo(img):\n",
    "    '''\n",
    "    Create a histogram from a SITK image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img (SITK image)\n",
    "    '''\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "    fig = plt.figure(figsize = (7,5))\n",
    "    ax = fig.gca()\n",
    "    ax.hist(arr.flatten(), bins = 255)\n",
    "    plt.show(fig)\n",
    "\n",
    "def plotImg(img, color = 'gray'):\n",
    "    '''\n",
    "    Plot a SITK image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img (SITK image)\n",
    "    color (string): the colour for image representation\n",
    "    '''\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "    plt.imshow(arr, cmap = color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c0299",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be8873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_001.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_001.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           57              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           80              M            PA                 2500     2048   \n",
       "4           74              F            PA                 2500     2048   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  \n",
       "0                        0.143  0.143  \n",
       "1                        0.143  0.143  \n",
       "2                        0.168  0.168  \n",
       "3                        0.171  0.171  \n",
       "4                        0.168  0.168  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CXR8/Data_Entry_2017_v2020.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934895b4",
   "metadata": {},
   "source": [
    "Sacamos los posibles labels que hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8479dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(df['Finding Labels'])\n",
    "labels = '|'.join(labels)\n",
    "labels = labels.split('|')\n",
    "labels = np.unique(labels).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03712b7e",
   "metadata": {},
   "source": [
    "Creamos una nueva columna por cada uno de los labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "144c432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in labels:\n",
    "    df[lab] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb381ee",
   "metadata": {},
   "source": [
    "Creamos una funcion para rellenar esas columnas por cada paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2161b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_label(information, label):\n",
    "    positive_labels = information.split('|')\n",
    "    if label in positive_labels:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd0bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map(objeto enumerado x: funcion(x, y), lista de x)\n",
    "for lab in labels:\n",
    "    df[lab] = list(map(lambda x: fill_label(x, lab), df['Finding Labels'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1780f",
   "metadata": {},
   "source": [
    "## Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63943111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_images(folder):\n",
    "    path = os.path.join(folder, 'images')\n",
    "    images_path = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    images = [sitk.ReadImage(os.path.join(path, image_path)) for image_path in images_path]\n",
    "    data = {'path': images_path, 'image': images}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1981ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [f.path for f in os.scandir('./CXR8/images/') if f.is_dir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05ce38",
   "metadata": {},
   "source": [
    "No se pueden cargar todas las imagenes así que solo he cargado la carpeta 1 y 2 (subfolders[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2481177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3352]\t22:16:02 INFO: [F]\tFolder ./CXR8/images/images_001\n",
      "[3352]\t22:17:21 INFO: [F]\tappending\n",
      "[3352]\t22:17:21 INFO: [F]\tstarting\n"
     ]
    }
   ],
   "source": [
    "keys = ['path', 'image']\n",
    "all_images = dict.fromkeys(keys)\n",
    "\n",
    "for folder in subfolders[0:1]:\n",
    "    logging.info('[F]\\tFolder {}'.format(folder))\n",
    "    group = folder.split('/')\n",
    "    folder_info = charge_images(folder)\n",
    "    try:\n",
    "        logging.info('[F]\\tappending')\n",
    "        all_images['path'][0].append(folder_info['path'])\n",
    "        all_images['image'][0].append(folder_info['image'])\n",
    "    except:\n",
    "        logging.info('[F]\\tstarting')\n",
    "        all_images['path'] = folder_info['path']\n",
    "        all_images['image'] = folder_info['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8efe7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = pd.DataFrame(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35b5242a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>[202, 199, 195, 193, 195, 194, 193, 192, 184, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>[208, 205, 206, 205, 207, 205, 207, 202, 204, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>[7, 10, 9, 8, 8, 8, 7, 7, 7, 6, 6, 7, 7, 6, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>[199, 175, 152, 133, 124, 118, 113, 111, 110, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>[69, 58, 49, 42, 36, 30, 25, 23, 20, 18, 16, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               path                                              image\n",
       "0  00000001_000.png  [202, 199, 195, 193, 195, 194, 193, 192, 184, ...\n",
       "1  00000001_001.png  [208, 205, 206, 205, 207, 205, 207, 202, 204, ...\n",
       "2  00000001_002.png  [7, 10, 9, 8, 8, 8, 7, 7, 7, 6, 6, 7, 7, 6, 6,...\n",
       "3  00000002_000.png  [199, 175, 152, 133, 124, 118, 113, 111, 110, ...\n",
       "4  00000003_000.png  [69, 58, 49, 42, 36, 30, 25, 23, 20, 18, 16, 1..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa85f9",
   "metadata": {},
   "source": [
    "Ahora voy a añadir datos a este nuevo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37a9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column(path, column):\n",
    "    value = df[column][df['Image Index'] == path]\n",
    "    value = list(value)[0]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f49aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images['neumonia'] = list(map(lambda x: get_column(x, 'Pneumonia'), all_images['path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3573c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "      <th>neumonia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>[202, 199, 195, 193, 195, 194, 193, 192, 184, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>[208, 205, 206, 205, 207, 205, 207, 202, 204, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>[7, 10, 9, 8, 8, 8, 7, 7, 7, 6, 6, 7, 7, 6, 6,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>[199, 175, 152, 133, 124, 118, 113, 111, 110, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>[69, 58, 49, 42, 36, 30, 25, 23, 20, 18, 16, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               path                                              image  \\\n",
       "0  00000001_000.png  [202, 199, 195, 193, 195, 194, 193, 192, 184, ...   \n",
       "1  00000001_001.png  [208, 205, 206, 205, 207, 205, 207, 202, 204, ...   \n",
       "2  00000001_002.png  [7, 10, 9, 8, 8, 8, 7, 7, 7, 6, 6, 7, 7, 6, 6,...   \n",
       "3  00000002_000.png  [199, 175, 152, 133, 124, 118, 113, 111, 110, ...   \n",
       "4  00000003_000.png  [69, 58, 49, 42, 36, 30, 25, 23, 20, 18, 16, 1...   \n",
       "\n",
       "   neumonia  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56a76528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images['image'][2].GetSize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60443d78",
   "metadata": {},
   "source": [
    "## Filtros sobre imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372afa55",
   "metadata": {},
   "source": [
    "### Equalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d49c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalizar(img):\n",
    "    '''\n",
    "    Equalize a SITK image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img (SITK image)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img (SITK image)    \n",
    "    '''\n",
    "    imgArr = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # Contrast stretching\n",
    "    p2, p98 = np.percentile(imgArr, (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(imgArr, in_range=(p2, p98))\n",
    "\n",
    "    # Equalization\n",
    "    img_eq = exposure.equalize_hist(imgArr)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    img_adapteq = exposure.equalize_adapthist(imgArr, clip_limit=0.03)\n",
    "    logging.info('[F]\\tend equalizar')\n",
    "        \n",
    "    return img_adapteq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images['equalizado'] = list(map(lambda x: equalizar(x), all_images['image']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f5cb3",
   "metadata": {},
   "source": [
    "## Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f447ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcdb87",
   "metadata": {},
   "source": [
    "Defino el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515fb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6422656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,451,554\n",
      "Trainable params: 6,451,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a39999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\María Rollán\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.000001)\n",
    "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e57a94",
   "metadata": {},
   "source": [
    "Cojo X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1ab0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:31 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:32 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:33 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:33 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:34 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:35 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:36 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:37 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:38 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:39 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:40 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:41 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:42 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:43 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:44 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:45 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:46 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:47 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:48 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:49 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:50 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:51 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:52 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:53 INFO: [F]\tend equalizar\n",
      "[3352]\t22:53:54 INFO: [F]\tend equalizar\n"
     ]
    }
   ],
   "source": [
    "X = list(map(lambda x: equalizar(x), all_images['image'][1:100]))\n",
    "Y = list(all_images['neumonia'][1:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2dbed",
   "metadata": {},
   "source": [
    "Divido en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58fa1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143202c7",
   "metadata": {},
   "source": [
    "Normalizo los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d2a15b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\n\u001b[0;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m      4\u001b[0m X_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, img_size, img_size, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "X_train.reshape(-1, img_size, img_size, 1)\n",
    "Y_train = Y_train\n",
    "\n",
    "X_test.reshape(-1, img_size, img_size, 1)\n",
    "Y_test = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567bf7d",
   "metadata": {},
   "source": [
    "Aumento del train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c47f5",
   "metadata": {},
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056ec0c",
   "metadata": {},
   "source": [
    "Entreno el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68c703d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py:985\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    982\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    984\u001b[0m   \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m--> 985\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    986\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    988\u001b[0m           _type_name(x), _type_name(y)))\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    990\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m           adapter_cls, _type_name(x), _type_name(y)))\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,epochs = 500 , validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac7297",
   "metadata": {},
   "source": [
    "Compruebo el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(500)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "print(classification_report(Y_test, predictions, target_names = ['No neumonia','Neumonia']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
