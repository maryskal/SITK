{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aae39819-bcdf-4ee7-960e-0730e915f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7607f877-5db2-4d2e-a207-b3ea8f62ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/mr1142/Documents/Data/models/neumonia_pediatric'\n",
    "modelos = os.listdir(p)\n",
    "modelos = [modelo[:-3] for modelo in modelos if os.path.isfile(os.path.join(p, modelo))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ea9bf433-a7f2-4fd3-8e82-5415c4281e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_2_0_00039000000000000005_512_binary_crossentropy_TT_auc-61',\n",
       " 'model_2_8_00035000000000000005_512_custom_loss_FT_auc-78',\n",
       " 'model_1_13_0007500000000000001_512_binary_crossentropy_FF_auc-58',\n",
       " 'model_1_13_0007500000000000001_512_binary_crossentropy_FF_auc-54',\n",
       " 'model_1_13_0007500000000000001_512_binary_crossentropy_FF_auc-55',\n",
       " 'model_2_2_-05_512_custom_loss_TT_auc-87',\n",
       " 'model_2_2_-05_512_custom_loss_TT_auc-90',\n",
       " 'model_2_2_-05_512_custom_loss_TT_auc-88',\n",
       " 'model_2_0_00039000000000000005_512_binary_crossentropy_TT_auc-62',\n",
       " 'model_2_8_00035000000000000005_512_custom_loss_FT_auc-72',\n",
       " 'model_2_8_00035000000000000005_512_custom_loss_FT_auc-83',\n",
       " 'model_1_1_00047000000000000004_512_custom_loss_FF_auc-61',\n",
       " 'model_1_1_00047000000000000004_512_custom_loss_FF_auc-85',\n",
       " 'model_1_8_0005700000000000001_256_custom_loss_TT_auc-78']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b6a37-07c1-4fc2-988b-958c8732222c",
   "metadata": {},
   "source": [
    "# COMPLETOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1f19868c-5395-4510-b917-9377105af0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mr1142/Documents/Data/models/neumonia_pediatric/training_data/train_max_pediatric.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b7c8efac-5511-42ea-86bc-5131845e449a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>pixels</th>\n",
       "      <th>mask</th>\n",
       "      <th>augment</th>\n",
       "      <th>frozen_layer</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>auc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>1.777301</td>\n",
       "      <td>0.884707</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>0.953086</td>\n",
       "      <td>17.132061</td>\n",
       "      <td>0.605683</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.547716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>0.648667</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.812515</td>\n",
       "      <td>0.940692</td>\n",
       "      <td>3.833833</td>\n",
       "      <td>0.553001</td>\n",
       "      <td>0.303624</td>\n",
       "      <td>0.553064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>17.503716</td>\n",
       "      <td>0.867609</td>\n",
       "      <td>0.803817</td>\n",
       "      <td>0.936594</td>\n",
       "      <td>13.571913</td>\n",
       "      <td>0.666028</td>\n",
       "      <td>0.414996</td>\n",
       "      <td>0.585151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model_1_1_00047000000000000004_512_custom_loss...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>8</td>\n",
       "      <td>10.028547</td>\n",
       "      <td>0.645813</td>\n",
       "      <td>0.466235</td>\n",
       "      <td>0.613687</td>\n",
       "      <td>12.413050</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.613506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>model_1_1_00047000000000000004_512_custom_loss...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>8</td>\n",
       "      <td>1.090470</td>\n",
       "      <td>0.612336</td>\n",
       "      <td>0.422727</td>\n",
       "      <td>0.563936</td>\n",
       "      <td>0.694869</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.613506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_2_0_00039000000000000005_512_binary_cros...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>8</td>\n",
       "      <td>0.665228</td>\n",
       "      <td>0.666188</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>0.615650</td>\n",
       "      <td>0.773145</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.484704</td>\n",
       "      <td>0.616396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_2_0_00039000000000000005_512_binary_cros...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>8</td>\n",
       "      <td>0.662066</td>\n",
       "      <td>0.668743</td>\n",
       "      <td>0.507794</td>\n",
       "      <td>0.621918</td>\n",
       "      <td>0.626653</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.495220</td>\n",
       "      <td>0.620459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_2_0_00039000000000000005_512_binary_cros...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>8</td>\n",
       "      <td>5.703353</td>\n",
       "      <td>0.665549</td>\n",
       "      <td>0.494243</td>\n",
       "      <td>0.619648</td>\n",
       "      <td>64.029663</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.491874</td>\n",
       "      <td>0.620459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>13.889109</td>\n",
       "      <td>0.771802</td>\n",
       "      <td>0.650647</td>\n",
       "      <td>0.836562</td>\n",
       "      <td>13.793877</td>\n",
       "      <td>0.673996</td>\n",
       "      <td>0.508712</td>\n",
       "      <td>0.724720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.844440</td>\n",
       "      <td>0.778949</td>\n",
       "      <td>0.664483</td>\n",
       "      <td>0.839341</td>\n",
       "      <td>3.251755</td>\n",
       "      <td>0.755258</td>\n",
       "      <td>0.740069</td>\n",
       "      <td>0.786321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>model_1_8_0005700000000000001_256_custom_loss_...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>8</td>\n",
       "      <td>1.010117</td>\n",
       "      <td>0.757946</td>\n",
       "      <td>0.631319</td>\n",
       "      <td>0.816260</td>\n",
       "      <td>1.499833</td>\n",
       "      <td>0.715743</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.788787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.876323</td>\n",
       "      <td>0.778829</td>\n",
       "      <td>0.665801</td>\n",
       "      <td>0.838586</td>\n",
       "      <td>3.517448</td>\n",
       "      <td>0.766890</td>\n",
       "      <td>0.670092</td>\n",
       "      <td>0.833077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model_1_1_00047000000000000004_512_custom_loss...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>8</td>\n",
       "      <td>13.071368</td>\n",
       "      <td>0.767178</td>\n",
       "      <td>0.647930</td>\n",
       "      <td>0.823135</td>\n",
       "      <td>13.075292</td>\n",
       "      <td>0.818008</td>\n",
       "      <td>0.728764</td>\n",
       "      <td>0.858380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-87</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.897030</td>\n",
       "      <td>0.819477</td>\n",
       "      <td>0.726745</td>\n",
       "      <td>0.888932</td>\n",
       "      <td>0.882650</td>\n",
       "      <td>0.805131</td>\n",
       "      <td>0.718232</td>\n",
       "      <td>0.872274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-88</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.945933</td>\n",
       "      <td>0.816083</td>\n",
       "      <td>0.721998</td>\n",
       "      <td>0.882794</td>\n",
       "      <td>0.818778</td>\n",
       "      <td>0.811823</td>\n",
       "      <td>0.727636</td>\n",
       "      <td>0.885696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-90</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.849636</td>\n",
       "      <td>0.824948</td>\n",
       "      <td>0.731650</td>\n",
       "      <td>0.891703</td>\n",
       "      <td>0.727391</td>\n",
       "      <td>0.832218</td>\n",
       "      <td>0.745163</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name    model  pixels   mask  \\\n",
       "1   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "2   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "0   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "12  model_1_1_00047000000000000004_512_custom_loss...  model_1     512  False   \n",
       "14  model_1_1_00047000000000000004_512_custom_loss...  model_1     512  False   \n",
       "7   model_2_0_00039000000000000005_512_binary_cros...  model_2     512   True   \n",
       "6   model_2_0_00039000000000000005_512_binary_cros...  model_2     512   True   \n",
       "8   model_2_0_00039000000000000005_512_binary_cros...  model_2     512   True   \n",
       "10  model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "9   model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "15  model_1_8_0005700000000000001_256_custom_loss_...  model_1     256   True   \n",
       "11  model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "13  model_1_1_00047000000000000004_512_custom_loss...  model_1     512  False   \n",
       "3             model_2_2_-05_512_custom_loss_TT_auc-87  model_2     512   True   \n",
       "5             model_2_2_-05_512_custom_loss_TT_auc-88  model_2     512   True   \n",
       "4             model_2_2_-05_512_custom_loss_TT_auc-90  model_2     512   True   \n",
       "\n",
       "    augment  frozen_layer            loss_type       lr  batch       loss  \\\n",
       "1     False            13  binary_crossentropy  0.00075      8   1.777301   \n",
       "2     False            13  binary_crossentropy  0.00075      8   0.648667   \n",
       "0     False            13  binary_crossentropy  0.00075      8  17.503716   \n",
       "12    False             1          custom_loss  0.00047      8  10.028547   \n",
       "14    False             1          custom_loss  0.00047      8   1.090470   \n",
       "7      True             0  binary_crossentropy  0.00039      8   0.665228   \n",
       "6      True             0  binary_crossentropy  0.00039      8   0.662066   \n",
       "8      True             0  binary_crossentropy  0.00039      8   5.703353   \n",
       "10     True             8          custom_loss  0.00035      8  13.889109   \n",
       "9      True             8          custom_loss  0.00035      8   0.844440   \n",
       "15     True             8          custom_loss  0.00057      8   1.010117   \n",
       "11     True             8          custom_loss  0.00035      8   0.876323   \n",
       "13    False             1          custom_loss  0.00047      8  13.071368   \n",
       "3      True             2          custom_loss  0.00005      8   0.897030   \n",
       "5      True             2          custom_loss  0.00005      8   0.945933   \n",
       "4      True             2          custom_loss  0.00005      8   0.849636   \n",
       "\n",
       "    binary_accuracy  precision       auc   val_loss  val_binary_accuracy  \\\n",
       "1          0.884707   0.830467  0.953086  17.132061             0.605683   \n",
       "2          0.867769   0.812515  0.940692   3.833833             0.553001   \n",
       "0          0.867609   0.803817  0.936594  13.571913             0.666028   \n",
       "12         0.645813   0.466235  0.613687  12.413050             0.666666   \n",
       "14         0.612336   0.422727  0.563936   0.694869             0.666666   \n",
       "7          0.666188   0.493258  0.615650   0.773145             0.666666   \n",
       "6          0.668743   0.507794  0.621918   0.626653             0.666666   \n",
       "8          0.665549   0.494243  0.619648  64.029663             0.666666   \n",
       "10         0.771802   0.650647  0.836562  13.793877             0.673996   \n",
       "9          0.778949   0.664483  0.839341   3.251755             0.755258   \n",
       "15         0.757946   0.631319  0.816260   1.499833             0.715743   \n",
       "11         0.778829   0.665801  0.838586   3.517448             0.766890   \n",
       "13         0.767178   0.647930  0.823135  13.075292             0.818008   \n",
       "3          0.819477   0.726745  0.888932   0.882650             0.805131   \n",
       "5          0.816083   0.721998  0.882794   0.818778             0.811823   \n",
       "4          0.824948   0.731650  0.891703   0.727391             0.832218   \n",
       "\n",
       "    val_precision   val_auc  \n",
       "1        0.395400  0.547716  \n",
       "2        0.303624  0.553064  \n",
       "0        0.414996  0.585151  \n",
       "12       0.484674  0.613506  \n",
       "14       0.484674  0.613506  \n",
       "7        0.484704  0.616396  \n",
       "6        0.495220  0.620459  \n",
       "8        0.491874  0.620459  \n",
       "10       0.508712  0.724720  \n",
       "9        0.740069  0.786321  \n",
       "15       0.576389  0.788787  \n",
       "11       0.670092  0.833077  \n",
       "13       0.728764  0.858380  \n",
       "3        0.718232  0.872274  \n",
       "5        0.727636  0.885696  \n",
       "4        0.745163  0.906273  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('val_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809de0a7-4e09-498f-af0e-075864e4ad5c",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0309513-cdeb-4a9e-92c2-147b446a4c56",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "baf2880c-6ed2-4a00-bb7f-b9adbec3e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mr1142/Documents/Data/models/neumonia_pediatric/validation_results/image_class_evaluation_pediatric.csv'\n",
    "df_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d7d792c2-2bda-424d-93e5-3f2821760df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>model</th>\n",
       "      <th>pixels</th>\n",
       "      <th>mask</th>\n",
       "      <th>augment</th>\n",
       "      <th>frozen_layer</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model_1_1_00047000000000000004_512_custom_loss...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>8</td>\n",
       "      <td>0.693528</td>\n",
       "      <td>0.656449</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>3.130645</td>\n",
       "      <td>0.573755</td>\n",
       "      <td>0.349845</td>\n",
       "      <td>0.535536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>1.455070</td>\n",
       "      <td>0.553001</td>\n",
       "      <td>0.300895</td>\n",
       "      <td>0.553064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>1.892277</td>\n",
       "      <td>0.575990</td>\n",
       "      <td>0.368275</td>\n",
       "      <td>0.580934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_2_0_00039000000000000005_512_binary_cros...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>8</td>\n",
       "      <td>0.615849</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_2_0_00039000000000000005_512_binary_cros...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>8</td>\n",
       "      <td>0.609334</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.689521</td>\n",
       "      <td>0.630019</td>\n",
       "      <td>0.447005</td>\n",
       "      <td>0.674941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model_1_8_0005700000000000001_256_custom_loss_...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>8</td>\n",
       "      <td>0.708675</td>\n",
       "      <td>0.720523</td>\n",
       "      <td>0.584080</td>\n",
       "      <td>0.765280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.665870</td>\n",
       "      <td>0.752868</td>\n",
       "      <td>0.735013</td>\n",
       "      <td>0.778791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.606236</td>\n",
       "      <td>0.774379</td>\n",
       "      <td>0.684297</td>\n",
       "      <td>0.822026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model_1_1_00047000000000000004_512_custom_loss...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>8</td>\n",
       "      <td>0.586227</td>\n",
       "      <td>0.818008</td>\n",
       "      <td>0.728764</td>\n",
       "      <td>0.858380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-87</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.548392</td>\n",
       "      <td>0.776769</td>\n",
       "      <td>0.651868</td>\n",
       "      <td>0.863475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-88</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.547818</td>\n",
       "      <td>0.816444</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.888501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-90</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.513435</td>\n",
       "      <td>0.822658</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.898118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               nombre    model  pixels   mask  \\\n",
       "11  model_1_1_00047000000000000004_512_custom_loss...  model_1     512  False   \n",
       "1   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "2   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "0   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "7   model_2_0_00039000000000000005_512_binary_cros...  model_2     512   True   \n",
       "6   model_2_0_00039000000000000005_512_binary_cros...  model_2     512   True   \n",
       "9   model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "13  model_1_8_0005700000000000001_256_custom_loss_...  model_1     256   True   \n",
       "8   model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "10  model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "12  model_1_1_00047000000000000004_512_custom_loss...  model_1     512  False   \n",
       "3             model_2_2_-05_512_custom_loss_TT_auc-87  model_2     512   True   \n",
       "5             model_2_2_-05_512_custom_loss_TT_auc-88  model_2     512   True   \n",
       "4             model_2_2_-05_512_custom_loss_TT_auc-90  model_2     512   True   \n",
       "\n",
       "    augment  frozen_layer            loss_type       lr  batch      loss  \\\n",
       "11    False             1          custom_loss  0.00047      8  0.693528   \n",
       "1     False            13  binary_crossentropy  0.00075      8  3.130645   \n",
       "2     False            13  binary_crossentropy  0.00075      8  1.455070   \n",
       "0     False            13  binary_crossentropy  0.00075      8  1.892277   \n",
       "7      True             0  binary_crossentropy  0.00039      8  0.615849   \n",
       "6      True             0  binary_crossentropy  0.00039      8  0.609334   \n",
       "9      True             8          custom_loss  0.00035      8  0.689521   \n",
       "13     True             8          custom_loss  0.00057      8  0.708675   \n",
       "8      True             8          custom_loss  0.00035      8  0.665870   \n",
       "10     True             8          custom_loss  0.00035      8  0.606236   \n",
       "12    False             1          custom_loss  0.00047      8  0.586227   \n",
       "3      True             2          custom_loss  0.00005      8  0.548392   \n",
       "5      True             2          custom_loss  0.00005      8  0.547818   \n",
       "4      True             2          custom_loss  0.00005      8  0.513435   \n",
       "\n",
       "    binary_accuracy  precision       auc  \n",
       "11         0.656449   0.484674  0.500000  \n",
       "1          0.573755   0.349845  0.535536  \n",
       "2          0.553001   0.300895  0.553064  \n",
       "0          0.575990   0.368275  0.580934  \n",
       "7          0.666666   0.000000  0.603131  \n",
       "6          0.666666   0.000000  0.624761  \n",
       "9          0.630019   0.447005  0.674941  \n",
       "13         0.720523   0.584080  0.765280  \n",
       "8          0.752868   0.735013  0.778791  \n",
       "10         0.774379   0.684297  0.822026  \n",
       "12         0.818008   0.728764  0.858380  \n",
       "3          0.776769   0.651868  0.863475  \n",
       "5          0.816444   0.732673  0.888501  \n",
       "4          0.822658   0.730570  0.898118  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sort_values('auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb95b0-92d7-4dfa-a655-92d7b6b2fca0",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0e51fa5f-8753-4ec8-a8dd-532b18399a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mr1142/Documents/Data/models/neumonia_pediatric/validation_results/prediction_validation_metrics.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "614281cf-7ef0-4500-acb4-6ed654c9c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['auc_mean'] = (df.auc_0 + df.auc_1 + df.auc_2)/3\n",
    "df['f1_score_mean'] = (df.f1_score_0 + df.f1_score_1 + df.f1_score_2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "aa3b13cd-14a4-4858-b79d-940ffd9f4722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>model</th>\n",
       "      <th>pixels</th>\n",
       "      <th>mask</th>\n",
       "      <th>augment</th>\n",
       "      <th>frozen_layer</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>auc_0</th>\n",
       "      <th>...</th>\n",
       "      <th>f1_score[0, 2]</th>\n",
       "      <th>precision_score[0, 2]</th>\n",
       "      <th>recall_score[0, 2]</th>\n",
       "      <th>accuracy_score[0, 2]</th>\n",
       "      <th>f1_score[1, 2]</th>\n",
       "      <th>precision_score[1, 2]</th>\n",
       "      <th>recall_score[1, 2]</th>\n",
       "      <th>accuracy_score[1, 2]</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>f1_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model_1_1_00047000000000000004_512_custom_loss...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>8</td>\n",
       "      <td>0.414985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316445</td>\n",
       "      <td>0.234909</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.316445</td>\n",
       "      <td>0.234909</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.467785</td>\n",
       "      <td>0.527187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_2_0_00039000000000000005_512_binary_cros...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316445</td>\n",
       "      <td>0.234909</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.316445</td>\n",
       "      <td>0.234909</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.527187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_2_0_00039000000000000005_512_binary_cros...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316445</td>\n",
       "      <td>0.234909</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.316445</td>\n",
       "      <td>0.234909</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.484674</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.527187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>0.974654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511844</td>\n",
       "      <td>0.729086</td>\n",
       "      <td>0.592912</td>\n",
       "      <td>0.592912</td>\n",
       "      <td>0.521440</td>\n",
       "      <td>0.733447</td>\n",
       "      <td>0.598659</td>\n",
       "      <td>0.598659</td>\n",
       "      <td>0.778896</td>\n",
       "      <td>0.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551659</td>\n",
       "      <td>0.686271</td>\n",
       "      <td>0.607280</td>\n",
       "      <td>0.607280</td>\n",
       "      <td>0.364256</td>\n",
       "      <td>0.455789</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.796870</td>\n",
       "      <td>0.516083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model_1_8_0005700000000000001_256_custom_loss_...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>8</td>\n",
       "      <td>0.969354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570013</td>\n",
       "      <td>0.785014</td>\n",
       "      <td>0.624521</td>\n",
       "      <td>0.624521</td>\n",
       "      <td>0.343439</td>\n",
       "      <td>0.753197</td>\n",
       "      <td>0.497126</td>\n",
       "      <td>0.497126</td>\n",
       "      <td>0.797943</td>\n",
       "      <td>0.686394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_1_13_0007500000000000001_512_binary_cros...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8</td>\n",
       "      <td>0.987495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544412</td>\n",
       "      <td>0.691256</td>\n",
       "      <td>0.604406</td>\n",
       "      <td>0.604406</td>\n",
       "      <td>0.545087</td>\n",
       "      <td>0.710690</td>\n",
       "      <td>0.608238</td>\n",
       "      <td>0.608238</td>\n",
       "      <td>0.799261</td>\n",
       "      <td>0.503612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.928644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679922</td>\n",
       "      <td>0.682189</td>\n",
       "      <td>0.680077</td>\n",
       "      <td>0.680077</td>\n",
       "      <td>0.512765</td>\n",
       "      <td>0.581849</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.817385</td>\n",
       "      <td>0.680740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.956095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727554</td>\n",
       "      <td>0.743124</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.705971</td>\n",
       "      <td>0.722440</td>\n",
       "      <td>0.708812</td>\n",
       "      <td>0.708812</td>\n",
       "      <td>0.839423</td>\n",
       "      <td>0.831766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model_1_1_00047000000000000004_512_custom_loss...</td>\n",
       "      <td>model_1</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>8</td>\n",
       "      <td>0.957861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704585</td>\n",
       "      <td>0.742625</td>\n",
       "      <td>0.711686</td>\n",
       "      <td>0.711686</td>\n",
       "      <td>0.546329</td>\n",
       "      <td>0.654903</td>\n",
       "      <td>0.587165</td>\n",
       "      <td>0.587165</td>\n",
       "      <td>0.843307</td>\n",
       "      <td>0.806804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model_2_8_00035000000000000005_512_custom_loss...</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.983058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726345</td>\n",
       "      <td>0.748638</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.533869</td>\n",
       "      <td>0.639717</td>\n",
       "      <td>0.576628</td>\n",
       "      <td>0.576628</td>\n",
       "      <td>0.893025</td>\n",
       "      <td>0.817592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-87</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.995371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.776446</td>\n",
       "      <td>0.740421</td>\n",
       "      <td>0.740421</td>\n",
       "      <td>0.583216</td>\n",
       "      <td>0.594880</td>\n",
       "      <td>0.587165</td>\n",
       "      <td>0.587165</td>\n",
       "      <td>0.906579</td>\n",
       "      <td>0.838689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-88</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719893</td>\n",
       "      <td>0.798338</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.736784</td>\n",
       "      <td>0.785255</td>\n",
       "      <td>0.744253</td>\n",
       "      <td>0.744253</td>\n",
       "      <td>0.908789</td>\n",
       "      <td>0.850893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_2_2_-05_512_custom_loss_TT_auc-90</td>\n",
       "      <td>model_2</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>custom_loss</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720425</td>\n",
       "      <td>0.809081</td>\n",
       "      <td>0.734674</td>\n",
       "      <td>0.734674</td>\n",
       "      <td>0.790236</td>\n",
       "      <td>0.808877</td>\n",
       "      <td>0.792146</td>\n",
       "      <td>0.792146</td>\n",
       "      <td>0.919007</td>\n",
       "      <td>0.866937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               nombre    model  pixels   mask  \\\n",
       "11  model_1_1_00047000000000000004_512_custom_loss...  model_1     512  False   \n",
       "6   model_2_0_00039000000000000005_512_binary_cros...  model_2     512   True   \n",
       "7   model_2_0_00039000000000000005_512_binary_cros...  model_2     512   True   \n",
       "2   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "0   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "13  model_1_8_0005700000000000001_256_custom_loss_...  model_1     256   True   \n",
       "1   model_1_13_0007500000000000001_512_binary_cros...  model_1     512  False   \n",
       "9   model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "8   model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "12  model_1_1_00047000000000000004_512_custom_loss...  model_1     512  False   \n",
       "10  model_2_8_00035000000000000005_512_custom_loss...  model_2     512  False   \n",
       "3             model_2_2_-05_512_custom_loss_TT_auc-87  model_2     512   True   \n",
       "5             model_2_2_-05_512_custom_loss_TT_auc-88  model_2     512   True   \n",
       "4             model_2_2_-05_512_custom_loss_TT_auc-90  model_2     512   True   \n",
       "\n",
       "    augment  frozen_layer            loss_type       lr  batch     auc_0  ...  \\\n",
       "11    False             1          custom_loss  0.00047      8  0.414985  ...   \n",
       "6      True             0  binary_crossentropy  0.00039      8  0.500000  ...   \n",
       "7      True             0  binary_crossentropy  0.00039      8  0.500000  ...   \n",
       "2     False            13  binary_crossentropy  0.00075      8  0.974654  ...   \n",
       "0     False            13  binary_crossentropy  0.00075      8  0.979628  ...   \n",
       "13     True             8          custom_loss  0.00057      8  0.969354  ...   \n",
       "1     False            13  binary_crossentropy  0.00075      8  0.987495  ...   \n",
       "9      True             8          custom_loss  0.00035      8  0.928644  ...   \n",
       "8      True             8          custom_loss  0.00035      8  0.956095  ...   \n",
       "12    False             1          custom_loss  0.00047      8  0.957861  ...   \n",
       "10     True             8          custom_loss  0.00035      8  0.983058  ...   \n",
       "3      True             2          custom_loss  0.00005      8  0.995371  ...   \n",
       "5      True             2          custom_loss  0.00005      8  0.994762  ...   \n",
       "4      True             2          custom_loss  0.00005      8  0.997616  ...   \n",
       "\n",
       "    f1_score[0, 2]  precision_score[0, 2]  recall_score[0, 2]  \\\n",
       "11        0.316445               0.234909            0.484674   \n",
       "6         0.316445               0.234909            0.484674   \n",
       "7         0.316445               0.234909            0.484674   \n",
       "2         0.511844               0.729086            0.592912   \n",
       "0         0.551659               0.686271            0.607280   \n",
       "13        0.570013               0.785014            0.624521   \n",
       "1         0.544412               0.691256            0.604406   \n",
       "9         0.679922               0.682189            0.680077   \n",
       "8         0.727554               0.743124            0.729885   \n",
       "12        0.704585               0.742625            0.711686   \n",
       "10        0.726345               0.748638            0.729885   \n",
       "3         0.733700               0.776446            0.740421   \n",
       "5         0.719893               0.798338            0.732759   \n",
       "4         0.720425               0.809081            0.734674   \n",
       "\n",
       "    accuracy_score[0, 2]  f1_score[1, 2]  precision_score[1, 2]  \\\n",
       "11              0.484674        0.316445               0.234909   \n",
       "6               0.484674        0.316445               0.234909   \n",
       "7               0.484674        0.316445               0.234909   \n",
       "2               0.592912        0.521440               0.733447   \n",
       "0               0.607280        0.364256               0.455789   \n",
       "13              0.624521        0.343439               0.753197   \n",
       "1               0.604406        0.545087               0.710690   \n",
       "9               0.680077        0.512765               0.581849   \n",
       "8               0.729885        0.705971               0.722440   \n",
       "12              0.711686        0.546329               0.654903   \n",
       "10              0.729885        0.533869               0.639717   \n",
       "3               0.740421        0.583216               0.594880   \n",
       "5               0.732759        0.736784               0.785255   \n",
       "4               0.734674        0.790236               0.808877   \n",
       "\n",
       "    recall_score[1, 2]  accuracy_score[1, 2]  auc_mean  f1_score_mean  \n",
       "11            0.484674              0.484674  0.467785       0.527187  \n",
       "6             0.484674              0.484674  0.500000       0.527187  \n",
       "7             0.484674              0.484674  0.500000       0.527187  \n",
       "2             0.598659              0.598659  0.778896       0.466600  \n",
       "0             0.474138              0.474138  0.796870       0.516083  \n",
       "13            0.497126              0.497126  0.797943       0.686394  \n",
       "1             0.608238              0.608238  0.799261       0.503612  \n",
       "9             0.560345              0.560345  0.817385       0.680740  \n",
       "8             0.708812              0.708812  0.839423       0.831766  \n",
       "12            0.587165              0.587165  0.843307       0.806804  \n",
       "10            0.576628              0.576628  0.893025       0.817592  \n",
       "3             0.587165              0.587165  0.906579       0.838689  \n",
       "5             0.744253              0.744253  0.908789       0.850893  \n",
       "4             0.792146              0.792146  0.919007       0.866937  \n",
       "\n",
       "[14 rows x 47 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('auc_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1f37b5a7-5f04-473c-b4d3-6d868d16cef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7691622076434663"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df.auc_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a9f642b8-a72c-46b5-9b0a-a2f787e79ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2b8fb6c0-f996-4040-b061-79d9aa203767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4, 1.0)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,5))\n",
    "p = sns.boxplot(x=\"model\", y='auc_mean',\n",
    "                hue=\"loss_type\",\n",
    "                data=df)\n",
    "p.set(ylim=(0.4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795b573-e589-4029-8652-baf4b11c7004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
