{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0314e01-4445-4021-8f13-0bf7664794fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications import EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b6b01-2ab1-48d6-bd0f-3ef54c92052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220cbd6-5dc3-4255-8ab4-dd4fc1ef2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficienNet = EfficientNetB4(weights=\"imagenet\", include_top=False, input_shape=(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ffa26-ccdc-40fe-a1e5-57af58c59e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(efficienNet.layers[326].output.shape)\n",
    "print(efficienNet.layers[149].output.shape)\n",
    "print(efficienNet.layers[90].output.shape)\n",
    "print(efficienNet.layers[31].output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f1b522-1e69-48de-8826-6dbb58b1f82b",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "https://www.nature.com/articles/s41598-022-12743-y/figures/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41903816-3eb8-457b-b304-36dda104eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efNet_conection(efNet_output):\n",
    "    x1 = layers.LeakyReLU()(efNet_output)\n",
    "    x2 = layers.MaxPool2D((2,2))(x1)\n",
    "    x3 = layers.Dropout(0.3)(x2)\n",
    "    return x3\n",
    "\n",
    "\n",
    "def decoder_subblock(encoder_output, prev_layer):\n",
    "    # https://www.nature.com/articles/s41598-022-12743-y/figures/3\n",
    "    unification = layers.concatenate([encoder_output, prev_layer])\n",
    "    x1 = layers.Dropout(0.3)(unification)\n",
    "    x2 = layers.Conv2D(3,3,padding = 'same')(x1)\n",
    "    x3 = residual_block(x2)\n",
    "    x3 = residual_block(x3)\n",
    "    x4 = layers.LeakyReLU()(x3)\n",
    "    return x4\n",
    "\n",
    "\n",
    "def residual_block(prev_layer):\n",
    "    path_1 = layers.LeakyReLU()(prev_layer)\n",
    "    path_1 = layers.BatchNormalization()(path_1)\n",
    "    path_1 = layers.Conv2D(3,3,padding = 'same')(path_1)\n",
    "    path_1 = layers.BatchNormalization()(path_1)\n",
    "    path_1 = layers.LeakyReLU()(path_1)\n",
    "    path_1 = layers.Conv2D(3,3,padding = 'same')(path_1)\n",
    "    path_1 = layers.BatchNormalization()(path_1)\n",
    "    path_2 = layers.BatchNormalization()(prev_layer)\n",
    "    return layers.concatenate([path_1, path_2])\n",
    "\n",
    "    \n",
    "def up_sampling(prev_layer, deep, kernel):\n",
    "    x = layers.Conv2DTranspose(deep, kernel)(prev_layer)\n",
    "    return x\n",
    "\n",
    "\n",
    "def last_up_sampling(prev_layer):\n",
    "    x = layers.Conv2D(1,1, padding='same', activation='sigmoid')(prev_layer)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0b0d4-4799-41dc-982a-f0b7bfb8bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_model():\n",
    "     # inputs\n",
    "    inputs = layers.Input(shape=(256,256,3))\n",
    "    \n",
    "    # adaptation = layers.Conv2D(3, 3, padding=\"same\", activation = \"elu\")(inputs)\n",
    "        \n",
    "    #EfficientNet\n",
    "    efficienNet = EfficientNetB4(weights=\"imagenet\",\n",
    "                                 include_top=False,\n",
    "                                 input_shape=(256,256,3),\n",
    "                                 input_tensor=inputs)\n",
    "    \n",
    "    efficienNet.trainable = False\n",
    "    \n",
    "    # ENCONDING\n",
    "    # (128,128,144)\n",
    "    dw1 = efficienNet.layers[31].output\n",
    "    # (64,64,192)\n",
    "    dw2 = efficienNet.layers[90].output\n",
    "    # (32,32,336)\n",
    "    dw3 = efficienNet.layers[149].output\n",
    "    # (16,16,960)\n",
    "    dw4 = efficienNet.layers[326].output\n",
    "\n",
    "    # Encoder sub block (8,8,960)\n",
    "    middle = efNet_conection(dw4)\n",
    "    \n",
    "    # DECODING\n",
    "    # (16,16,960)\n",
    "    uc1 = up_sampling(middle, dw4.shape[3],9)\n",
    "    up1 = decoder_subblock(dw4, uc1)\n",
    "    \n",
    "    # (32,32,336)\n",
    "    uc2 = up_sampling(up1, dw3.shape[3],17)\n",
    "    up2 = decoder_subblock(dw3, uc2)\n",
    "    \n",
    "    # (64,64,192)\n",
    "    uc3 = up_sampling(up2, dw2.shape[3],33)\n",
    "    up3 = decoder_subblock(dw2, uc3)\n",
    "    \n",
    "    # (128,128,144)\n",
    "    uc4 = up_sampling(up3,dw3.shape[3],65)\n",
    "    up4 = decoder_subblock(dw1, uc4)\n",
    "\n",
    "    uc5 = up_sampling(up4,16,129)\n",
    "\n",
    "    # outputs\n",
    "    outputs = last_up_sampling(uc5)\n",
    "\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3144c-058e-416d-a030-47fe65adb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = build_unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd108c11-6afc-49fc-afbd-0adc1e896c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unet_model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb21301-9a9b-426a-8a93-70f54952053b",
   "metadata": {},
   "source": [
    "Vamos a entrenar a partir de la capa 327, que es la ultima del modelo preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4e57e-de03-47b0-ba53-ee24da83ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 327\n",
    "\n",
    "for layer in unet_model.layers[:327]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b5a4d-aaad-4bc1-a85f-b491db60305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unet_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26830d6a-f9ba-4fd1-8662-ce86f701602b",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ee36e-fb4b-41cc-8a1d-a4dabfc0c8a4",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/Users/maryskal/Documents/SITK/CXR8/images/images_001'\n",
    "# path = '/home/mr1142/Documents/Data/seg_prueba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165386ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_name = os.listdir(os.path.join(path, 'mascara'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a66f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path, folder, img):\n",
    "    img = cv2.imread(os.path.join(path, folder, img))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (pixels, pixels))\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c49956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return (img - np.mean(img))/ np.std(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(img):\n",
    "    img[img>0] = 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.zeros((len(masks_name), pixels,pixels,1))\n",
    "for i in range(len(masks_name)):\n",
    "    masks[i, ...] = binarize(read_img(path, 'mascara', masks_name[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.zeros((len(masks_name), pixels,pixels,1))\n",
    "for i in range(len(masks_name)):\n",
    "    images[i, ...] = normalize(read_img(path, 'images', masks_name[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281895f-d450-4d62-9f09-fb6f1f1cda0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(0, len(images))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(masks[r])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(images[r])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb54e1-5ac8-49bc-830f-fd06e8ce15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751c7376-b779-4c57-b44e-51e3d17624a1",
   "metadata": {},
   "source": [
    "## Selección de pesos por imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7fd25a-d004-4ed6-a7c0-19435c51aff7",
   "metadata": {},
   "source": [
    "Vamos a ver las imagenes y elegir las de peor calidad para darles más peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3061a-3fc3-4d60-91e1-5aeec3d9a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(images)):\n",
    "#     print(i)\n",
    "#     plt.figure(figsize=(100, 100))\n",
    "#     plt.subplot(1,len(images),i+1)\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71ddc4-3eb8-483c-bce5-4dadb39f3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_quality = [14,15,34] + [i for i in range(39,56)] + [65,73,76,77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3471a6c-bd59-41d1-96ff-4c369fae46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = np.array([1 if i in bad_quality else 0.75 for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c432e8fb-03e0-4b50-907c-27e2fd1ea47e",
   "metadata": {},
   "source": [
    "# Aumento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a22fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(input_image, input_mask):\n",
    "    r = np.random.randint(-60,60)\n",
    "    # Random flipping of the image and mask\n",
    "    input_image = np.expand_dims(imutils.rotate(input_image, angle=r),  axis=-1)\n",
    "    input_mask = np.expand_dims(imutils.rotate(input_mask, angle=r), axis=-1)\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b74df3-0a1c-49c4-ad91-54c20f943351",
   "metadata": {},
   "source": [
    "Nuevas imagenes con rotacion random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.zeros((len(masks_name), pixels,pixels,1))\n",
    "new_mask = np.zeros((len(masks_name), pixels,pixels,1))\n",
    "for i in range(len(masks_name)):\n",
    "    img, mask = augment(images[i], masks[i])\n",
    "    new_img[i, ...] = img\n",
    "    new_mask[i,...] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1942df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate((new_img, images), axis = 0)\n",
    "masks = np.concatenate((new_mask, masks), axis = 0)\n",
    "importance = np.concatenate((importance, importance), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f129f3-4b87-4e18-83c0-a44d231b9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(0, len(images))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(images[r])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(masks[r])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e73236",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f78d0-808a-4ba6-99fd-64e7c98f3392",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"'D:/Users/maryskal/Documents/logs\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                      update_freq='batch',\n",
    "                                                      histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "datagen.fit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\", \"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 8\n",
    "epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0413dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = unet_model.fit(images,masks,\n",
    "                         batch_size = batch,\n",
    "                         epochs = epoch,\n",
    "                         callbacks = tensorboard_callback,\n",
    "                         sample_weight = importance,\n",
    "                         shuffle = True,\n",
    "                         validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
